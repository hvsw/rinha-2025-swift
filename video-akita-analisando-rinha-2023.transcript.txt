Olá pessoal Fábio aquita se costuma acompanhar a comunidade de desenvolvimento no Twitter talvez tenha ouvido falar que em agosto de 2023 aconteceu um mini evento online chamado de rinha de backend organizado pelo Zan francesc desenvolvedor experiente atualmente trabalhando no nubank Eu não conhecia ele e só fiquei sabendo que esse evento aconteceu quase uma semana depois que já tinha acabado mesmo se soubesse antes eu não teria participado porque nunca fui de competições ratons ou algo assim mas eu gostei muito do que os participantes fizeram e sem querer isso tomou boa parte do meu tempo incluindo várias noites mal dormidas sem sombra de dúvidas Esse vai ser o vídeo mais trabalhoso que eu já fiz na história desse canal não só esse como o próximo hoje eu vou resumir minha saga de 16 dias do pós rinha avaliando diversos projetos dos participantes e nesse percurso Eu Aprendi muita coisa nova que eu não sabia ou que eu achava que fosse diferente foi uma longa Saga muitas noites noites mal dormidas frustração ansiedade crises existenciais suor e lágrimas é bastante coisa e só o resumo vai dar um vídeo de mais de uma hora por isso eu vou pedir muita paciência de vocês vai ter várias técnicas importantes que eu vou mencionar o nome e os efeitos que causam Mas vai ser bem por cima se ficarem confusos com termos que parecem complicados Não se preocupem eu vou explicar os detalhes no próximo também vai ser nesse próximo que eu vou falar detalhes das linguagens que eu vou mencionar Então segurem as críticas hoje quero só compartilhar como foi minha gerou alguma controvérsia pelo que eu ouvi falar daí eu vou contar o que pensei a respeito e como eu resolvi começar a abrir os projetos dos participantes com uma missão fazer todo mundo chegar no primeiro lugar Como eu disse antes Eu não participei do evento nem acompanhei o dia a dia acho que o desafio foi lançado do primeiro mas ninguém sabia exatamente como seriam os critérios para definir o vencedor até dias depois e parte da Graça de uma rinha como essa não é ser uma competição Tecnicamente perfeitamente justa tem muito fator sorte e Incerteza envolvido como em qualquer Esporte Nem sempre é o melhor atleta técnico que ganha todos os jogos Mas quem aprendeu mais nos jogos anteriores quem consegue se adaptar rápido e quem teve menos azar assim foi essa rinha também por isso em nenhum momento em Car em qualquer coisa que parece uma crítica como uma crítica ao evento e sim como dicas pros próximos minha discussão vai ser puramente técnica a crítica real vai para quem tentou levar isso a sério demais ser torcedor apaixonado de um time é normal agora sair xingando e brigando na rua quando vê o cara do outro time é ser um animal irracional imbecil eu vou assumir que eu tô falando com homo sapiens e não com neandertais o desafio foi divulgado no repositório de github do Zan que eu vou deixar o link nas descrições abaixo Aliás sempre Olhem a descrição de todo o vídeo eu coloco links para várias coisas extras para vocês além de ter a descrição de todos os capítulos para ficar mais fácil achar sessões de vídeos longos como esse enfim Leiam as instruções do desafio mas em resumo o objetivo era escolher qualquer linguagem de programação com ou sem Framework implementar quatro end points de apis e configurar para rodar com docker compose numa configuração específica de infraestrutura fazer a api em si em qualquer linguagem é super simples é um endpoint post barra pessoas que recebe um json simples com dados como apelido nome data de nascimento e stack de programação um arrei com elementos como o PHP ou Java é como se fosse o cadastro de um sisteminha de recrutamento ou algo assim tem que validar que apelido tem no máximo 32 letras nome no máximo 100 letras data de nascimento tem que ser minimamente válido inclusive ele não fala que 31 de Fevereiro tem que ser inválido só fala que o formato tem que ser ano tracinho MS tracinho dia a lista de stack tem que ser um arrei sem elementos nulos e cada elemento não podia ter mais que 32 letras e finalmente o ID tinha que ser um uuid que é um tipo de número aleatório Isso foi um bom requerimento Como eu vou mostrar mais paraa frente mas em termos de validação era só isso se passar dados Inválidos Temos que devolver o cabeçalho http 400 de Bad request ou se voltar erro no insert do SQL por causa de constraints inválidas como nome não poder ser nulo apelido já existia ou algo assim tem que devolver cabeçalho http 422 de erro unprocessable entity a resposta paraa requisição de criação precisa ter o cabeçalho http 201 created e um cabeçalho location com o caminho para essa pessoa recém criada no formato get barpa barid isso é comum numa api restful básica esse endp devolvido no location deve conseguir encontrar a pessoa recém criada e devolver o json com os dados se passar um um uuid que não existe tem que devolver o cabeçalho htt TP de 404 not found depois precisava ter outro endp get bar pessoas que receba um parâmetro chamado t para ser um termo de procura para pesquisarmos esse termo no apelido ou nome ou na stack Seria tipo fazer um SQL com apelido like termo or nome like termo or stack like termo e eu já vou explicar porque esse seria o pior jeito devolvemos o resultado em Jason com código http 200 ou devolve código 400 de erro se não passar termo nenhum não encontrando nada bastava devolver um Jason com arrei vazio em vez de 400 not found e finalmente o end Point era um simples get Contagem pessoa que deveria fazer um count na tabela e devolver quantas inserções de fato aconteceram Esse é o único end Point que não faz parte do stress Test e isso pode se tornar um ponto importante para alguns truques como eu vou explicar no próximo vídeo como podem ver são end points super triviais se você é um programador experiente eu tenho certeza que já tem de cabeça como Faria na sua linguagem mais fluente dá para fazer rapidinho uma versão que funciona em uma duas horas se tiver um pouco enferrujado mesmo se for bem iniciante seguindo qualquer tutorial de APS Rash full no Framework que tiver aprendendo é para conseguir fazer em um dia essa é a ordem de grandeza e talvez sirva para vocês saberem que pé estão vai demorar mais do que isso Se quiser experimentar técnicas diferentes teve versão que eu levei uns dois dias para terminar porque eu resolvi aprender um Framework novo do zero por exemplo no próximo vídeo vou demonstrar como dá para fazer uma versão simples em poucos minutos por agora só acreditem que dá aliás eu vou começar a listar coisas pro próximo episódio mostrar como fazer uma versão simples do zero mas agora vem a parte que separa os adultos das Crianças a infraestrutura não basta só fazer o código e dizer roda na minha máquina tem que rodar dentro das restrições da rinha Então não é só subir um banco de dados subir sua aplicação sozinha e acabou segundo as regras tem que subir duas instâncias da sua aplicação para rodar em paralelo e ambos precisam ficar embaixo de um balanceador de carga no caso pediram engex no mundo real aplicações rodam com várias instâncias em paralelo embaixo de um balanceador de um kubernetes sisso h proxy ou várias outras alternativas azuri tem o application Gateway aws tem o elb o elastic load balance tem o Traffic F5 Big IP e mais mas emx é fácil e simples o suficiente para esse desafio não é o mais rápido mas também não é o mais difícil de usar e Aqui começa a parte realmente difícil uma Instância de nginx uma Instância de banco de dados que pode ser postgress mysle ou mung DB Mas duas instâncias da sua aplicação sendo balanceadas precisam caber em um CPU e meio e no máximo usar 3 GB de Ram e só essa é a regra da rinha fazer a api não é o desafio mas essa limitação que é tudo bem fazer cabê é fácil o problema mesmo é que no final esse sistema tem que aguentar um stress teste um teste de carga stress teste é um teste automatizado que simula como pessoas ou sistemas consumiriam o seu sistema mandando requisições http pros end points da api no caso Eles escolheram a ferramenta gatling que tem versão aberta e uma paga com mais recursos a versão gratuita razoavelmente simples de usar e o script pro cenário de carga tá no github da rinha vamos anotar aqui para eu explicar o básico de stress Test no próximo vídeo lembrando que quando a rinha começou eu acho que os participantes ainda não Tin tinham acesso a esse script de testes justamente para não tentar burlar os critérios eu não sei se eles sequer tiveram acesso ao script durante a rinha Eu imagino que não só no final vamos assumir que ninguém sabia isso que diferencia os participantes da rinha de programadores como eu agora que tem a oportunidade de avaliar sabendo tudo que eles não sabiam não compare o meu resultado com o deles isso seria injusto em resumo você podia escolher linguagem Framework e implementar uma aplicação web que serve quatro end points de apis tinha que que ser o mais leve possível para aguentar carregar duas instâncias mais nginx mais banco em 1.5 CPU e 3 GB de Ram orquestrado por docker compose eu ainda não fiz um vídeo explicando o que é um Framework web então vamos anotar aqui para explicar no próximo vídeo eu já tinha feito um vídeo sobre docker Eu recomendo que assistam depois mas aí também no próximo eu vou explicar como usar o docker composer para subir todos os componentes de um sistema web na sua máquina também a ideia é que os participantes deviam empacotar a aplicação numa imagem de docker subir no docker Hub postar o arquivo de docker compos como pull request no github da rinha E aí os organizadores iam rodar esse docker compose e aplicar algum teste de carga quem passasse ia pro ranking final o ranking foi interessante teve 90 participantes e desses 39 foram desclassificados por diversas razões ou o docker compose tinha algum bug nem carregava ou alguns dos end points da p não respondiam como deveriam ou deixaram de implementar alguma coisa que tinha nas regras sobraram 51 projetos que funcionaram mais da metade um número respeitável e no final além de implementar os end points corretamente o resultado pro ranking foi baseado na quantidade de inserts que foram feitos no banco de dados ordenando a lista por essa quantidade de inserts tivemos os top 10 Quem ganhou a rinha foi o Vinicius Fonseca com sua implementação usando Rust com o Framework attic com Tokyo e em segundo lugar ficou o Léo Vargas com sua versão em go e Fiber o Framework que usa Fest http em terceiro ficou o André maha e Albert kimk que fizeram em dupla uma versão em dnet 8 com csharp em quarto ficou a Isadora Souza que também usou go com Jin em quinto ficou a dupla algebraic a Sofia e a Gabi que fizeram em lin 4 a linguagem mais desconhecida da rinha depois eu vou falar delas em sexto ficou o Vinícius Santos que também fez em Rust em sétimo ficou o Jean Rodriguez que também fez em Gol em oitavo ficou o luí picano com outra versão em Rust em nono e também em 10mo ficou o Rodrigo Navarro que participou com duas versões de Rust uma feita com o Framework axon e outra com o mais leve touchet que por ironia ficou depois da versão em axon aliás parece que ele fez pelo menos uma dessas versões numa Live no canal dele para quem se interessar corre atrás para assistir portanto nos top 10 ficou assim cinco versões em Rust três versões em go um em LM e um em dnet aí as redes sociais foram a louca primeiro ninguém achou estranho já que isso confirma a hegemonia do Rust e do go como as linguagens mais rápidas da atualidade pior ainda o fato de dar um dnet nos top 10 mas não um Java fez um monte de gente ficar ridicularizando o Java sabe o que eu falei do torcedor de time neandertal sim Afinal na cabeça deles Java é uma linguagem velha ultrapassada certo vamos ver como os neandertais leram o resto do ranking seguindo pros próximos 10 em 11º ficou o Gabriel Oliveira com uma versão em elixer alguns ficaram tipo puts não era o elixer que Você vendia como rápido Perdeu até pro dnet em 12º ficou o Lucas William com uma versão em c+ Plus ué c+ Plus não era para ser mais rápido Rust e go são [ __ ] mesmo muito melhor que c+ Plus em 13º ficou o Lucas Wise com uma versão em node JS com Express é pois é bem que me falaram que JavaScript não é tudo isso que falam né em 14º ficou Yuri Gomes que fez uma versão em Ban antes do lançamento da versão 1.0 alguns dias atrás e Pois é bang é só Hype mesmo nem lançou ainda e já é lento em 15º ficou o thalis macial que fez em Rust também pô coitado deve ser um Júnior né não é culpa do Rust em 16º ficou um cara de apelido sem brisson que não deixou arquivo de ridm para trás com o nome então eu nem fui tentar procurar em 17º ficou o Lauro apelt com sua versão em PHP Finalmente uma linguagem que se associa mais com web clássica quem diria PHP na não morreu mas tá lá embaixo com pezinho na Cova né E só em 18º ficou o Bruno Borges com a primeira versão em Java da rinha e só para piorar a situação do Java ele ficou encostado no 19º que foi o Lázaro Nixon com uma versão em Ruby on rails e o Vio do Leandro Proença que também fez uma versão em Ruby pera aí Java tá tão ruim agora que fica encostado em Ruby que faz hein eu queria parar no 20º mas só no 21º lugar tivemos o Yan cambrea com a primeira são em Python usando o Sonic na competição Pelo visto Python também é só Hype né não ganhou nem de PHP nem de ru nem de Java e eu espero que vocês que acompanharam não tenham pensado desse jeito porque seria vergonhoso Dentro os 51 projetos enviados oito foram feitos em go sete em JavaScript seis em Rust seis em Java cinco em PHP qu em dnet TRS em Python dois em Ruby dois em elixir um em c+ Plus um em LM e o último lugar foi feito feito em Bash pelo Leandro teve uns três no ranking que o ridm não dizia em que linguagem foi feita e nem o link pro github Então eu também não fui atrás para saber o LM da Sofia e Gabi foi o mais inesperado Ainda mais por ter entrado nos top 10 e o último de BES do Leandro foi o mais inusitado porque eu acho que nem ele esperaria ganhar com isso mas quis se apresentar e mandou super bem e sim best de terminal que vocês usam no Linux como Shell tem gente que roda do numa calculadora porque não uma aplicação webin Bash mas nesse caso como esperado BH não tinha como competir mesmo alguns participaram com mais de uma implementação como o Leandro que fez em Ruby BH o Lauro apelt com duas versões em PHP o Rodrigo Navarro com duas em Rust e eu não sei como foi a divulgação do Zan francesc mas ele mandou muito bem foi uma participação bem variada e ao meu ver cumpriu exatamente o que eu imaginava de uma rinha galos de diferentes tamanhos e cores Rust e go na frente JavaScript e Java para trás é o que a plateia gostaria de ver foi show de bola tendo visto os resultados se no topo tivesse sido uma hegemonia absoluta de Rust e go provavelmente eu teria aceitado como todo mundo sim talvez nessas restrições de infra Só eles mesmo para aguentar carga mas como tinha um dotnet ali na terceira posição e meus parabéns pro André e Albert por isso mas isso chamou minha atenção eu não vejo porque dtnet consegue estar nos top 10 e outra linguagem não seja Java ou JavaScript com essa pulga atrás da orelha minha Saga começa na sexta-feira dia 25 de agosto eu abri o editor e comecei a fazer a minha versão eu tava um pouco enferrujado então levei acho que umas Du horas para implementar em rubion rails mesmo levou mais tempo do que deveria porque eu pensei hum se é um teste de carga e inserção Talvez o postgre seja o gargalo depois do http post o teste Vai checar se inseriu pelo id não tem como deixar só em memória porque são duas instâncias isoladas como tem balanceador de carga o normal vai ser inserção cair numa Instância e a pesquisa cair na outra Instância a conclusão imediata que qualquer um chegaria é eu vou colocar um Cash compartilhado Talvez um Men Cash Mas como eu queria já lidar com o que eu achei que fosse o gargalo eu pensei vou jogar Jobs em fila de redis para inserir em background Então esquece Men Cash eu vou usar redis tanto como Cash quanto fila de Jobs deve caber nas restrições de Ram porque aí o postgres deve trabalhar um pouco menos e eu divido os recursos pelo que avaliei depois não fui só eu que pensei assim várias das versões fizeram a mesma coisa usaram redis ou nats como Cash e fila de Jobs assíncrono é uma coisa que todos nós que já temos cicatriz de guerra fazemos meio sem pensar e isso é um sério problema não existem soluções automáticas cada caso é um caso e precisa ser medido antes de implementar qualquer truque cash ou filas não deixam nada rápido automaticamente em todo caso eles também custam recursos e de novo vamos deixar anotado aqui para eu explicar no próximo vídeo como é essa estratégia de usar Jobs e filas para inserir e porque cash não fazia diferença aqui pelo mesmo motivo eu achei que fosse ver mais gente usando mongo DB assumindo que muitos imaginam que é mais rápido mas do total de 90 projetos só sete tentaram e mesmo mais Cico só dois tentaram a maioria esmagadora acreditou no postgres por padrão a conclusão coisas relativamente fáceis como adicionar Cash filas todo mundo faz na frente coisas mais complicadas Como mudar o paradigma de armazenamento aí deixamos para depois eu também escolhi ID de postgres sendo eu criador de conteúdo que por 20 anos vem evangelizando coisas como uso de poges Cash Jobs assíncronos com redias me deu uma pontinha de dor na consciência mesmo aqui no canal eu já fiz um vídeo chamado tornando sua app web mais rápida onde eu faço justamente essas recomendações eu tento explicar Em que casos usar mas eu acho que dá para explicar isso em mais detalhes por isso eu deixei anotado para voltar nesse assunto no próximo vídeo quando Terminei minha versão de rails Com cash Jobs tudo mais rodei o stress test já imaginava que poderia não ser rápido mas sempre tem aquela pontinha de esperança de vai né e Para minha decepção não deu mais que uns 15.000 inserts abaixo ainda das versões de rails do Lázaro e do Leandro foi quando eu comecei a postar tudo que eu ia descobrir no Twitter e esse foi o meu primeiro tweet Olha que situação ridícula Quem gera esses relatórios é a própria ferramenta gatling que roda o teste de carga no próximo o vídeo eu vou mostrar como ele funciona nesse gráfico interessa a Barrinha verde Olha como tá lá embaixo e a vermelha tá lá em cima é a quantidade de knockouts ou Chaos ko de requisições que não conseguiram ser processadas e foram Perdidas em resumo só entenda que queremos que Verde seja grande e vermelho seja pequeno ou idealmente zero nesse momento eu pensei é talvez essa carga seja muito pesada para uma linguagem interpretada como Ruby numa infra de docker tão apertada resolvi baixar a versão do Leandro que usa Ruby mas sem Framework pesado como o rails e os resultados dele foram bem melhores que os meus mas ainda assim tem uma Barra Vermelha considerável de knockouts eu conseguia 15.000 inserts e a versão dele batia de 30.000 inserts na minha máquina na minha cabeça Essa discrepância fazia sentido eu imagino que façam na de vocês também afinal quanto menos coisa tiver mais rápido deveria ficar só para testar os limites eu tirei a restrição de 1.5 CPU e 3 GB de Ram e configurei o docker compose para usar 24 cpus e 20 GB de Ram Afinal meu PC aguenta muito mais que isso assim a Barrinha verde de fato sobe mas olha que ainda tem uma barrinha vermelha eu ainda tô perdendo requisições e Para para pensar isso não faz sentido em nenhuma linguagem nesse ponto as coisas não estavam fazendo muito sentido bacana eu sei que Rust go são rápidos Afinal são compilados e tal mas se o problema fosse só falta de recurso na minha máquina que é absurdamente potente não deveria est dando nenhum knockout isso foi aumentando a pulga atrás a minha orelha a conclusão nunca pode ser ah linguagem uma bosta a primeira conclusão sempre tem que ser eu tô fazendo alguma coisa errada e ir atrás de descobrir o quê resolvi tentar uma outra versão aproveitar o domingo dia 27 de Agosto fazia algum tempo que eu queria desenferrujar o meu Crystal e aprender o Framework web chamado Luck ótima Desculpa deixei a documentação do site aberta de um lado e editor do outro e fui fazendo tentativas minha premissa é que Crystal sendo uma linguagem que compila binário nativo como go deveria ser bem mais rápido que minha versão em rails e no final eu gastei o domingo inteiro mais a segunda-feira seguinte para fazer porque eu nunca tinha usado o Luck antes vamos anotar isso também pro próximo vídeo falar um pouco mais das minhas experiências mexendo em linguagens diferentes mas para hoje só precisa entender que os criadores do Crystal o Ari e o Brian quiseram inventar uma linguagem com sintaxe mais próximo possível de Ruby adicionando coisas modernas como inferência de tipos fibers channels mas com perfil de performance similar de GO em alguns casos até de Rust foi nesse ponto que eu fui vendo outros desenvolvedores na comunidade começarem a esmiuçar mais os critérios do ranking em particular o Mr Power gamer br sendo jave iro ele foi um dos que ficaram sofrendo bullying do Povo tirando o sarro do Java ter se saído tão mal no ranking em vez de só sair dando reply xingando todo mundo como todo Twitter faz ele fez O que um programador de verdade deveria fazer abrir o código e provar com números ele fez a mesma coisa que eu começou uma nova versão na linguagem que mais gosta cotlin para quem não sabe cotlin foi inventado pela Jet Brains a empresa que faz a ideia intelij e o Android Studio Eu também gosto dela e eu vou deixar anotado para comentar a respeito no próximo vídeo para hoje basta entender que é compatível com Java e Tecnicamente oferece a mesma performance dia 28 de agosto ele postou essa versão que não Só melhora a posição de Java mas iguala na mesma posição top 1 da versão de Rust do Vinícius Fonseca e mais do que isso Ele estudou mais a fundo o script de stress Test em gatling e determinou que existe um número máximo de requisições e de inserts possível durante os 3 minutos fixos do teste 46.57 inserts na verdade vai ser 46.500 ou 600 alguma coisa porque no script de teste do gatlin tem essa chamada para randomized que afeta a quantidade de requisições para criação de registros se rodar o teste várias vezes vai dar números diferentes Eu imagino que o Zan francesc fez isso de propósito para adicionar o fator de sorte no espírito de uma rinha Portanto o resumo numérico nunca foi pensado para ser totalmente justo e antes que os haters apareçam de novo eu tô super Ok com isso mais do que isso o Mr Power gamer br olhou com mais calma a versão de Rust do Vinícius sim ele tava inconfor formado e nada é mais motivador do que a força do ódio ele notou que surgiam inconsistências esquisitas Às vezes o total dava 300 a mais do que o máximo às vezes dava 500 a mais como que isso podia ser possível não tem como aparecer requisições do nada se existe um máximo e passa do máximo obviamente existe um bug e de fato tem não foi de propósito a gente esquece bugs por isso sempre falamos não é porque uma linguagem compila não é porque uma linguagem tem checagem de tipos que não precisa de testes no código do Vinícius tem uma rotina de aquecimento que insere mais de 500 registros falsos não sabemos por mas depois tem o código que deleta isso só que esse código tem uma Race condition uma condição de corrida um erro clássico de programação concorrente ou seja Às vezes a rotina de limpeza roda antes de terminar de inserir tudo aí sobra registros e isso polui o total no final não chega a ser um problema porque mesmo se corrigir esse bug ainda assim a versão dele atinge o máximo Então sempre seria o primeiro mas estudando stress test estudando o código do Vinícius também do Lucas Wi que fez in no DJs o Mr Power Gamer aprendeu que existem truques que poderiam ser usados que a maioria não pensou não foram só eles mas alguns pensaram além do Óbvio e conseguiram resultados melhores em 10 de setembro o Mr Power gamer br soltou um vídeo detalhando essas descobertas Eu recomendo que assistam depois eu vou explicar tudo que ele falou e muito mais no próximo vídeo uma dessas técnicas foi book insert a outra técnica foi gerar um índice especial para pesquisas vamos deixar anotado aqui pro próximo vídeo explicar o que são book inserts e explicar como fazer pesquisas Fuzzy no postgress e os segredos de ajustes de performance se consertar o bug de Race condition do código do Vinícius e se tirar o fator de aleatoriedade do stress test o ranking fica bem diferente como o Mr Power Gamer mostra nos seus tweets o primeiro lugar seria compartilhado entre a versão de Rush do Vinícius que continua sendo o primeiro mas a versão de Godo Leonardo Vargas também sobe para primeiro assim como o sexto lugar da Isadora e o nono lugar do Navarro que também viraria primeiro lugar por causa disso o terceiro lugar de dnet do André e Albert pula pro segundo lugar eles raspam no máximo mas não ultrapassam por meros 65 insertos o quinto lugar do Luiz picano em Rush sobe para terceiro lugar o Navarro que tinha feito duas implementações em Rush também sobe a outra versão do 10mo para quarto o oitavo lugar do Jean Rodrigues ing sobe para quinto todo mundo vai subindo no ranking mas ainda sabendo o número máximo de inserts se alguma versão ultrapassar sabemos que tem bug nas validações E isso aconteceu com o quarto lugar em lim da Sofia e da Gabi e aqui ficou em sétimo lugar do Vinícius Santos em Rust ambos ultrapassam os 48.500 e tanto mas como tinha aquele fator de aleatoriedade no Script na rodada oficial passaram batido mas deviam ter sido desclassificados E que fique claro que não foi de propósito que atire a primeira pedra quem nunca deixou um bug para trás como eu já expliquei numa rinha tem fator sorte e tá ok o problema é que o script de stress Test e o critério de ranking não tinham sido divulgados desde o começo e nem testam tudo que tá nas instruções por exemplo eles deveriam checar as constantes da ddl e do SQL que cria a tabela e índices para garantir que coisas como apelido tem índice de unicidade que o campo de data de nascimento era realmente tipo data e coisas assim se fizer um campo de nascimento ser um varchar um string e simplesmente inserir o que viess sem checar no final vai ter mais registros do que deveria ter se fosse para ser mais rígido deveriam ter implementado uma rotina de testes automatizados em cpress por exemplo uma Suit de teste de aceitação que testam todas as regras que estão nas instruções assim seria possível ver se a aplicação tá devolvendo os códigos de erro quando enviamos dados inválidos sem isso vários bugs passam despercebido fica a dica para uma próxima rinha e também para projetos de verdade sem testes tudo compila tudo roda mas bugs de validação vão passar despercebido em todas as linguagens compiladas tipadas ou não vou repetir não encarem como uma crítica A rinha o próprio nome rinha é para ser uma brincadeira Inclusive eu acho que se tivesse um teste de aceitação mais rígido assim teria muito menos participante e muito mais projetos desclassificados e meio que perderia a graça mas o que me motivou a gastar tanto tempo nisso é que só olhando o ranking oficial sem todo o contexto Eu também tava aceitando que rails ou Java iam ser lentos mesmo e bola pra frente mas à medida que eu fui explorando que o Vinícius o Lucas o Leandro o Mr Power Gamer fizeram nas versões deles resolvi copiar na minha versão de Crystal para tirar a prova dos nove não era para ser difícil na minha cabeça coisa de poucas horas eu demorei um tanto para entender o Framework Luck O avran que é o ORM que fala com o banco tive até que abrir o código fonte deles para entender na dúvida na falta de documentação ou stack overflow Eu nunca penso duas vezes eu vou ler direto na fonte vantagem de usar projetos de código aberto é que o código é aberto sacaram é para ler e eu fiquei empolgado em tentar implementar o sistema de cche com Job assíncrono para fazer book insert como o Vinícius fez em Rust sendo Crystal compilado era para ter performance similar né LED do engano assim que eu terminei e fui testar com o gatlin a decepção lembra a Barrinha vermelha Olha ela aqui firme e forte minha implementação nem entraria nos top 20 meros 20.000 inserts só que diferente do que eu tava pensando sobre Ruby que é lento por ser interpretado não tinha o que fazer ou o Java que come muita Ram não tinha o que fazer aqui eu fiquei meio puto a culpa não podia ser do Crystal nem do Lucky tinha que ser minha eu tava fazendo alguma coisa muito errada será que eu sou uma farça será que eu sou sou tão ruim assim quando gastamos um tempo tentando descobrir um problema num código depois de ver tudo ou achar que viu tudo ainda assim não encontra Eu sempre tenho uma saída que funciona olhem esse código de Crystal para passar o stress teste basta devolver http 21 created e um location válido pra próxima requisição até tinha deixado comentado aqui esse código de teste eu posso descomentar essas duas linhas e comentar todas as de baixo é isso mesmo na dúvida Tire tudo e faça a resposta mais simples e idiota devolver uma constante mas essa location não vai existir porque se não inserir nada não existe ninguém com ID número um então no show. CRR também tinha deixado essa linha comentada que sequer tenta fazer a pesquisa no banco só devolve outra constante eu descomento e comento o resto pro teste de consulta passar certo basta devolver http 200 de Ok finalmente na pesquisa para termos mesma coisa descomento essa linha para devolver código 200 e comento o rest resto só fazendo isso o teste de carga já passa essa vai ser a velocidade máxima desse App sem processar nada no banco manjam eu tô removendo uma das variáveis de incerteza rodando o gatlin só esperar 3 minutos e esse é o resultado tudo verde nenhum vermelho de Noca e olhem aqui do lado todos os tempos de resposta da ordem de 1 mso na verdade é menos de 1 mso mas ele é redonda Esse é o tempo perfeito porque a aplicação não tá fazendo praticamente nada ótimo e isso mostra como Crystal sozinho é rápido agora eu posso ir voltando o meu código uma linha de cada vez eu salvo subo o docker compose que vai recompilar a imagem e rodo o getlin de novo checo e vejo se a diferença no resultado condiz com o código exra que eu coloquei volto descomento mais uma linha salvo reinicio o docker compose testo de novo meço e eu vou fazendo isso uma linha de cada vez e como esperado nenhuma dessas coisas extras deu nada de estranho até eu chegar nessa linha a que monta a URL de location a única coisa que isso vai fazer é gerar uma linha como essa aqui em cima um http dois pontos BL BL local roo blá blá blá Claro esse método faz mais do que só concatenar Strings serve para montar todo tipo de URL complexa que quiser incluindo encode de parâmetros e tudo mais imagina aquelas urls gigantes da Amazon mas eu nunca esperaria isso causar qualquer diferença significativa na realidade isso tá até errado eu pensei melhor e location na realidade só precisa devolver o pef só a parte de barra pessoas barid não precisa do protocolo nem domínio a menos que eu queira redirecionar o cliente consumindo Api para outro domínio diferente que não é o caso substituindo o método pon URL para ponto PF e testando de novo batata agora o resultado melhorou eu tweetei sobre isso daí uma conta da comunidade Crystal retweetou e um dos desenvolvedores do Framework Lucky o Jeremy ficou interessado ele foi tão legal que abriu uma lixo no projeto eu fui lá para explicar esses detalhes ele já tinha uma suspeita em mente e me pediu para testar um ajuste e esse foi meu post no Ticket aberto quando eu testei sem o pet dele tava tomando knockouts mas colocando o pet caiu de mais de 600 knockouts para menos de 10 Então tinha alguma regressão de performance mesmo eu não sei explicar exatamente o motivo ainda a versão anterior parece que só concatena Strings e o pet usa algum tipo de string builder concatenar era duplicatas de string um builder pré aloca espaço e vai só adicionando as novas partes sem duplicar é um tradeoff de CPU por Ram eu sei que isso faz alguma diferença mas não sei ainda explicar porque faria a diferença aqui mesmo tendo não devia ser significativo Mas de qualquer forma no número de stress test do getlin fez muita diferença sem querer eu acabei achando um gargalo de performance no Framework que levou a um conserto é assim que a gente acaba contribuindo em projetos open source sem querer mas essa não era a única única otimização olhando outras versões eu notei que ninguém estava devolvendo mensagens de erro completas como apelido já existe ou formato de data inválida as instruções Só falam que precisa devolver código de status 400 ou 422 na minha versão antes além do código eu devolvia um Jason com o erro e processar Jason também custa tempo eu tirei todos os métodos de render ou Jason e usei só o método head que como o nome diz devolve só o cabeçalho o código de erro é uma coisa besta que em testes individuais não faria diferença mas o getlin manda centenas de milhares de requisições aí parece que faz alguma diferença mesma coisa logs o teste não exige logs no mundo real precisamos ter mensagens de erro gravadas e retornadas para ficar mais fácil achar bugs e defeitos mas para esse desafio de performance que só dura 3 minutos podemos desligar todos os logs e ganhar alguns milissegundos importantes e fazendo pequenos ajustes assim o resultado de inserts de Crystal foi subindo dos pios 15 inserts foi para 30.000 daí para quase 40.000 inserts Eu não bati no máximo mas chegando perto dos 40.000 inserts já foi um salto muito bom quando eu postei esse resultado já era dia primeo de Setembro ainda me Distraí no processo Porque eu queria uma biblioteca para auxiliar o cashing em redis mas não tinha nenhum bem feito eu esbarrei num Bem antigo chamado kiwi que ninguém atualizava Fazia tempo então eu resolvi arrumar o código dela e essa foi minha segunda pequena contribuição open source enquanto isso em paralelo o Leandro e o Lázaro das versões de Ruby minimum e de Ruby on rails continuaram fazendo ajustes nas versões deles o Lázaro que no rank oficial da rinha tinha ficado lá na 19ª posição com uma faixa de 24.000 inserts também saiu ajustando as configurações dele com um pouco de ajuste já tinha conseguido bater os 40.000 inserts também o Leandro também com esses resultados Eles já teriam entrado nos top 10 o Leandro experimentou mais com as configurações de postgis e de engex muitos de nós achávamos que esses dois componentes não eram tão importantes pior achávamos que eles não ajudavam em nada então fizemos outra coisa feia que muitos fazem sem pensar colocamos emex para aceitar o máximo de conexões quanto possível aumentando o número de worker Connection lá para cima de 10.000 e no caso do posts a gente configurava os pulls de conexão para dezenas centenas de conexões e isso foi um enorme erro vamos anotar para explicar no próximo vídeo mas deixa eu tentar ilustrar aqui para ter uma visão na cabeça vamos imaginar uma lanchonete com vários caixas tirando pedido e mandando pros cozinheiros atrás os caixas são Nossa aplicação feitos em qualquer das nossas linguagens os cozinheiros são as conexões do banco de dados que é a cozinha o engex é como o tamanho da porta da lanchonete se fizer uma porta que aguenta passar 100.000 pessoas de uma só vez o que que acontece o stress teste começa com poucas pessoas umas três mas ao longo de 3 minutos dispara 60 simultaneamente só que essas seis não são atendidas ao mesmo tempo não tem caixa suficiente daí vai formar um amontoado de gente desordenado do lado da cozinha o banco de dados cada cozinheiro Extra exige pelo menos 3 m de Ram de espaço e vai consumir CPU mas a cozinha é limitada lembra da regra da rinha no máximo 1.5 CPU não adianta aumentar cozinheiro infinitamente que a cozinha não aguenta se falarmos pros caixas tirarem quantos pedidos conseguirem rapidamente esses pedidos vão ficar empilhados porque não tem cozinheiro suficiente para atender a vontade é aumentar os cozinheiros o pool de conexões digamos temos duas instâncias da aplicação os caixas e cada um vai poder tirar até 100 pedidos de uma só vez Então 200 pedidos mas não tem como ter 400 cozinheiros primeiro porque eles ocupam espaço 3 M cada já vai dar no mínimo 1.2 GB de Ram Mas beleza o estabelecimento inteiro aguenta 3 GB que é o limite imposto pela rinha lembra mas não tem fogão suficiente para cozinhar a cozinha tá tá apertada temos menos de um CPU cada cozinheiro vai demorar mais e mais tempo para atender cada pedido entenderam então o cenário é assim a porta do estabelecimento permite entrar todo mundo de uma só vez 1000 pessoas 10.000 pessoas entra tudo só tem dois caixas duas instâncias mesmo tirando pedido rápido fica tudo acumulado esperando não adianta contratar mais cozinheiro porque a cozinha é limitada e quanto mais cozinheiro tentamos colocar mais cada cozinheiro demora e enquanto o pedido na não é atendido a pessoa fica lá pendurada na frente do caixa esperando e assim Vai acumulando centenas de pessoas na lanchonete esperando até começarem a perder a paciência e ir embora são as requisições perdidas ou knockouts a solução que o Leandro publicou não é intuitiva em vez de fazer o engex aceitar quantas pessoas puder fazemos diferente limitamos o tamanho da porta digamos no máximo 1000 pessoas o engex coloca um sistema de senha do lado de fora e vai deixando entrar só 1000 de cada vez de forma mais ordenada é igual num Poupa Tempo ou no seu banco pega a senha senta e espera ser chamado agora os caixas atendem menos pessoas de uma vez mais ordenado e tiram menos pedido de uma só vez digamos no máximo 50 em vez de 100 ou 200 Esse é o pull de conexões e na cozinha em vez de precisarmos de 300 ou 400 cozinheiros agora precisamos só de 100 mas aí não vai andar mais devagar não porque sobra mais espaço na cozinha e cada cozinheiro consegue cozinhar mais rápido é melhor 100 cozinheiros terminando os pratos em um minuto ou 400 cozinheiros levando 10 minutos cada porque estão disputando o fogão entenderam eu tava cometendo esse erro também tava deixando nginx lá para cima com portão gigante para suportar 10.000 conexões e compensando com 200 conexões no Pool de cada Instância do rails E para piorar ainda estava cometendo um erro no postgis eu tinha essa linha no docker compose isso diz pro docker compose pegar esse arquivo pogs sql.com do meu diretório local e copiar para dentro do contêiner de posts mas estava faltando modificar o comando de inicialização para ter traço c com o nome desse arquivo É nesse arquivo que eu digo pro posts que ele deve suportar digamos o máximo de 400 conexões como não estava carregando o arquivo subia com o limite padrão de 100 conexões e isso confunde porque eu pensava que ia abrir mais de 100 mas não ia e eu não sabia por esse foi o primeiro motivo de porque meus resultados estavam lá na casa dos 15.000 insertos nesse caso faltava cozinheiro E eu achava que tinha suficiente falta de atenção que chama isso e em vez de consertar no lugar certo eu ficava tentando compensar em outros lugares como no nginx no próximo episódio eu vou explicar como eu poderia ter evitado essa confusão vamos deixar anotado aqui Depois que eu descobri isso e li o tweet do Leandro e reconfigure o engex pra faixa de 1000 workers de conexão e diminui o número de cozinheiros no Pool de conexões para uns 40 O problema nem era o máximo de conexões era a compensação excessiva que eu tava fazendo no engex um erro levando a outro erro a medida que eu ia diminuindo esses dois números passava a aumentar a quantidade de insertos No final a quantidade de pessoas atendidas de fato eu tava achando que minha versão de rails pelo fato de ter exagerado na solução e enfiado sair de Kick para Jobs redis pra fila Cash ia faltar espaço na tal cozinha mas não foi isso foi questão de gerenciar o fluxo de pessoas limitar a porta e os caixas em vez de escancarar lembrem-se disso atendimento não é tentar atender todo mundo de uma só vez é atender grupos organizados de cada vez é uma questão de vazão e fluxo isso é essencial em operações seja atendimento numa lanchonete seja numa linha de fábrica seja num servidor web e foi assim que em 3 de fevereiro postei o resultado da minha versão de rails faixa de 39.000 inserts quase batendo os 40.000 que eu queria o cenário que eu descrevi de gerenciar o fluxo de pessoas na lanchonete é um caso clássico que demonstra que o problema não é a capacidade de atendimento do caixa ou de cozinhar dos cozinheiros é de gerenciar o fluxo de requisições das pessoas ou sessões é quando sabemos que o problema principal é gerenciar io entrada e saída nós que somos mais experientes já Deveríamos ter parado para pensar nisso primeiro mas Assumimos errado no começo e essa hipótese errada nos fez perder muito tempo Assumimos que o problema seria a cozinha o banco de dados Aí tentamos compensar aumentando o número de cozinheiros ou cozinheiros mais rápidos que seriam os cashes seria o caso se o problema fosse CPU Bound limitação de CPU mas na realidade era problema de fluxo de entrada e saída no fluxo dos caixas o problema era io Bound como a maioria dos problemas de web comum uma vez controlado o fluxo podemos otimizar o caixa para em vez de só tirar pedido e ficar esperando de braços cruzados enquanto o cozinheiro tá ocupado esse caixa pode fazer outras coisas na frente como receber o pagamento pegar bandeja separar refrigerante limpar o balcão não precisa esperar o prato chegar para depois fazer tudo isso dá para fazer em paralelo É Para Isso que Servem trads ou usar cink a weight de várias linguagens como JavaScript no node JS nesse ponto eu já tinha visto Mr Power Gamer e outros colaboradores como o Bruno Borges conseguindo subi cotlin e Java pro mesmo nível do Rust Eu já vi o Leandro e o Lázaro subindo Ruby rails para perto do mesmo nível faixa dos 40.000 inserts eu mesmo já tinha conseguido subir Crystal e rails foi quando minha intuição dizia que a maioria dos participantes se tivessem conhecimento de tudo que a gente descobriu até agora seriam capazes de chegar perto desses 40.000 insertos ou Até bater o máximo dos 46.500 do Rust do Vinícius alguns não Gostaram de ouvir isso porque agora aquele bullying qu contra o Java ou a Fan boiss de Rust perderiam o valor e como eu detesto dizer uma coisa sem ter provado antes resolvi fazer a única coisa racional demonstrar na prática ainda era a mesma segunda-feira 4 de setembro eu escolhi começar aleatoriamente mexendo na versão em node JS Express do Lucas vi que já estava perto do Topo na faixa de 34.000 insertos em 13º lugar no ranking oficial na minha máquina tava dando abaixo disso uns 27.000 inserts a versão dele foi uma das que eu mexi mais como foi um código feito paraa competição ele e muitos outros não se preocuparam em seguir boas práticas Clean code nem nada disso só cuspiram o código até funcionar e publicaram Não tem absolutamente nada de errado nisso e não considerem Esses códigos como representação do que eles conseguem fazer com mais tempo em projeto de verdade isso tem que ser repetido o tempo todo código para competição é diferente de código de verdade mas como eu tava com tempo e não era para participar da competição aproveitei para desenferrujar meu JavaScript e fui refaturar um pouco o código para ficar mais organizado e mais legível meu objetivo era totalmente diferente da rinha dar uma limpada e otimizar o suficiente para bater pelo menos a faixa dos 40.000 inserts o que elevaria o projeto pros top cinco oficiais recomendo que lei o meu P request com calma eu deixei o link na descrição do vídeo abaixo mas em resumo depois de organizar o código comecei tirando a otimização prematura de usar redis como Cash como eu falei antes o problema não era a velocidade dos cozinheiros o pogs portanto a solução não era tentar achar cozinheiro mais rápido um redis com a configuração adequada do fluxo de engex do Pulp posts dividindo CPU e RAM melhor no docker compose já resolvia Arranquei o redis fora daí teria mais recursos pro postgres esse Cash além de tudo não tava sendo efetivo porque o Lucas tentava cachear os resultados do endp de pesquisa por termos só que o stress teste manda pesquisas com com termos aleatórios raramente repetidos então o Cash nunca ia ajudar porque toda a pesquisa ia ser nova e não ia ter o resultado do Cash portanto Cash na pesquisa de termos era inútil só um peso a mais de gravar no cash Além disso no endp de criar novo registro ele deixava o banco de dados criar a chave primária daí recebia de volta no final e só aí gravava no cash isso tem que acontecer um atrás do outro não dá para ser assíncrono adicionar o valor no cash só aumentar o tempo na requisição mais uma vez era um trabalho extra sem benefício no endp seguinte de pesquisar a pessoa direto por ID ele buscava no cash mas a pesquisa por chave primária no postgress é igualmente rápido de novo o Cash não fazia diferença só faria diferença se primeiro gerar a chave primária com a biblioteca de uuid na aplicação e mandar o insert pro banco já com essa id e em paralelo já mandar gravar no cash também com a mesma ID como não precisa esperar o banco devolver uma nova id não precisamos esperar para gravar no cash entenderam É uma das vantagens de usar um gerador de Chaves primárias externo ao banco muito iniciante não sabe que não é obrigatório deixar o banco responsável por ids O Lucas também tava devolvendo códigos de erro http junto com mensagens em Jason descrevendo erro mas a rinha não se incomodava com isso então só Arranquei fora o stress teste não liga paraa mensagem só quer respostas rápidas no mundo real o certo é dar respostas completas Porque sem logs bem descritos depois fica difícil achar bugs e problemas novamente é uma otimização que só serve para uma competição o node JS tem recurso de cluster subir forques do mesmo processo para escalar melhor mesma coisa que o rails também faz o Lucas parece que experimentou mas desistiu eu ia tirar fora mas eu voltei e passei a usar para tentar distribuir um pouco mais a carga ter um reactor com cor rotinas assíncronas e conseguir ter concorrência é de diferente de ter paralelismo e o ideal é ter as duas coisas eu explico isso no vídeo de concorrência e paralelismo e no próximo vídeo talvez eu tento explicar melhor esse contexto vamos deixar anotado a parte que Possivelmente pesou mais na versão do Lucas foi o end Point de pesquisa que faz select like na tabela muitos erraram nisso precisa fazer select like nas colunas apelido nome stack então é apelido like termo or nome like termo or stack like termo Esse é o pior jeito de fazer select o melhor jeito é pré-carnaval a segunda coisa foram as validações validar os dados antes de inserir no banco costuma ser mais rápido do que tentar inserir e deixar o banco devolver o erro por exemplo que a data de nascimento é inválida tipo mês 13 ou dia 31 em fevereiro podemos Só checar se a string tem o formato de ano tracinho mês tracinho dia no mínimo ou tentar converter essa string num objeto válido de data para garantir Eu não medi Exatamente esse ponto mas o Lucas usou a biblioteca moment.js que antigamente já foi bem Popular mas acho que é considerada meio obsoleta o jeito mais popular hoje é usar outra biblioteca a date fns ou simplesmente usar o constructor da classe date do JavaScript Nativo eu comecei tentando usar o date fns mas achei mais fácil Só checar se o parce da string para um New date is not a Number Com todas essas mexidas eu fui mexer no docker compos Ele tava subindo três instâncias de node no docker Mas como eu reativei o Code de node cluster Desci para dois cada um com um fork Extra totalizando quatro processos diminuí a carga do código de Cash que não estava servindo para nada melhorando as pesquisas por termo diminuindo a carga do código de validação ou seja fazero fazendo nossos caixas trabalhar menos em seguida era o problema de diminuir a montanha de gente que o endex estava deixando entrar tudo de uma só vez Diminuir a quantidade de workers do nginx dos Absurdos 20.000 para 10.000 até 1024 não ten que uns 1000 é ideal pra maioria das aplicações muitos até menos fazendo isso os caixas trabalham de forma mais organizada e eficiente precisando de menos cozinheiros menos conexões de banco no Pool o Lucas tinha configurado com 200 mas agora dava para descer para uns 45 talvez até menos e fazendo tudo isso essa versão de node JS saiu da faixa de 27.000 inserts na minha máquina ou 34.000 que conseguiu na máquina dos organizadores da rinha e pulou pra faixa dos 40.000 também do meu ponto de vista Foi uma mudança significativa e c Mou na minha cabeça que dava para fazer a mesma coisa pras outras versões e desculpas ao Lucas por ter pego ele para ajudas aqui mas não entendam errado vários outros Incluindo eu mesmo comete temos os mesmos erros eu só aproveitei para explicar mais na versão dele para não me repetir em todos os próximos enfim ainda no dia 4 de setembro depois de atingir os 40.000 insertos com o node JS resolvi mexer em outro velho conhecido elixir na minha cabeça não fazia sentido elixir tesse saído abaixo dos top 10 mas eu fiquei surpreso com o problema essa versão do Gabriel Oliveira se recusava a carregar na minha máquina como chegou a figurar no ranking oficial significa que o Zan conseguiu rodar para avaliar portanto se a é a mesma e tem que ser é a mesma imagem de docker por exclusão tem que ser alguma coisa na minha máquina mas toda vez que eu tentava subir o docker compose Eu vi as instâncias de App crashando sem nenhuma mensagem de erro simplesmente morriam Puff zero nada sem entender o motivo eu fiz um teste mudei o comando do docker compose para só subir um slip Infinity do Linux todo mundo conhece o conceito de slip certo pausa o processamento pelo tempo que manda Linux suporta Infinity daí fica pausado para sempre como um Loop Infinito w true da vida fazendo isso o contêiner fica de pé para eu poder fuçar daí é possível usar o comando docker compose eec para abrir um Dash dentro do contêiner de dentro Eu tentei executar o binário do app na mão e de fato Crash Ava isso eu achei muito estranho aí me ocorreu Será que o app é muito pesado eu vou tentar carregar o IX que é só a linha de comando do rapple do elixir sem carregar nada da aplicação e Crash Ava também estranhíssimo vamos pular o elixir e carregar direto só o erlang o comando erl e cachava bizarro A sensação que eu fiquei é que os programas pediam mais recursos do que a máquina conseguia entregar e cachava como falta de Ram resolvi editar o arquivo de docker compose para tirar a limitação da rinha de CPU e RAM tentando rodar de novo aí subia por alguma razão tava faltando Ram eu abri o h top para ver quanto de Ram tava usando e era um absurdo coisa de quase 1 GB5 eu fiquei bem confuso como fazia tempo que eu não mexia com El elixer fiquei pensando ué Será que nos últimos anos eles enfiaram tanta coisa no elixer que agora precisa de mais memória que jvm do Java é confuso porque quem já mexeu com web de Java com Spring e tudo sabe que 1 GB de Ram não é fora do comum mas eu não esperava isso do elixer e eu tava quase jogando a toalha então resolvi reportar no meu Twitter todo mundo achou estranho mas o próprio Gabriel conseguiu achar a resposta era o limite máximo de portas que o erlang detectava no meu sistema em erlang portanto em elix portas são usadas para se conectar com o mundo externo por exemplo para ler do standard input stdi ou escrever no standard output STD out são portas para abrir arquivos para receber conexões de rede são portas erlang pré aloca no mínimo 1024 ports para determinar o máximo podemos abrir o Shell erl e rodar o comando airl System info port limit e olha só meu sistema devolve mais de 1 milhão de portas daí tem o detalhe que eu ainda não entendi na aplicação e elixer parece que tenta pré-albumina iria faltar memória no contêiner crashando na inicialização felizmente com uma simples variável de ambiente erl Max Sports podemos colocar um número mais sano tipo 2048 ou algo assim limitando de 1 Milhão para 2.000 fez uma [ __ ] diferença agora o app sobe consumindo na faixa de 100 60 MB por Instância que é bem mais razoável e próximo até de versões como rails ou node Isso é um problema que só aconteceu no meu sistema porque a configuração de Arc Linux é mais agressiva nos limites do que um Debian ou o bunto que são mais conservadores sendo mais específico isso é limite de file descriptors o limite do sistema depois pesquisem sobre isso de qualquer forma a versão elixir do Gabriel eu gostei bastante porque usou características exclusivas de elixir ele fez as duas instâncias rodando em em contêiners diferentes se conectarem num cluster cluster saem de graça em erlang porque a máquina virtual já traz toda a infraestrutura pronta é fácil de usar não serve para tudo mas quando precisa é bem útil lembram como eu falei que não valia a pena usar um Cash como redis primeiro porque o postgis já era rápido o suficiente mas também porque subir um contêiner de redis significa dar menos recursos pro postgres com o recurso de cluster do airl dá para ter um Cash compartilhado entre as duas instâncias sem precisar de um redise entre os dois o app em elixir consegue consultar na memória da Primeira Instância e a Segunda instância no outro contêiner consegue pedir para essa primeira instância porque tão no mesmo cluster assim não precisam de uma memória externa na forma de um redis da vida a primeira vista Isso parece mais esperto mas como eu já disse antes o problema não é o postgress e adicionar um sistema de Cash só adiciona peso desnecessário mesmo assim essa versão ajustando só innex e o pud de conexões consegue passar dos 41.000 inserts e entraria nos top cinco mas tem um porém além do Cash as instâncias faziam chamadas RPC entre eles Ou seja a primeira instância podia pedir paraa Segunda instância gravar ou pesquisar no banco e vice-versa isso eu achei desnecessário e adiciona uma comunicação externa via rede para toda a chamada eu não tive tempo de testar eu acho que se arrancar fora essas chamadas remotas o código de Cash e dar mais recursos pro postgis Talvez seja possível eu conseguir um resultado melhor mesmo assim eu esperava que elixir conseguisse um número maior e de todas as versões que eu mexi essa ainda foi a que perfumou um pouco pior então tem espaço para simplificar mais o código elixir certamente consegue mais então notando o padrão em vez de adicionar coisas eu tô tirando coisas e com isso deixando mais rápido por isso sempre repetimos tanto que otimização prematura é a raiz de todo o mal com a versão elixir do Gabriel batendo acima dos 40.000 inserts resolvi procurar uma versão em golang e Escolhi um dos que ficou mais embaixo no ranking a do Luan ficou em 23º lugar com só 21.000 inserts assim como elixer não tem porque go ficar lá embaixo isso já se provou porque pelo menos três versões tinham alcançado os top 10 eu fiz pequenos ajustes no docker compose para dar um pouco menos de CPU paraas instâncias de app assumindo que go sem nenhum Framework iria precisar de menos recursos que elixir aí podemos aumentar CPU do post teve duas modificações de código que eu quis fazer primeiro erros devolverem só os códigos de erro 400 ou 422 http sem mensagens de erro é pouca coisa mas já faz um pouco de diferença a segunda coisa é que ele estava usando regular expressions para validar o formato da data de nascimento na real eu acho que isso é meio besteira mas como o regex costuma ser mais lento do que dar Split na string checar cada componente eu troquei também acho que nenhuma dessas duas coisas faz muita diferença no final o que deu diferença Sim foi o que eu já falei antes primeiro diminui o tamanho da porta de entrada diminuir os 10.000 workers de Engine next para 1024 e aumentar o pull de conexões embora isso também nem tenha sido necessário só de limitar e controlar o fluxo de entrada de requisições literalmente uma linha já disparou o resultado da faixa de 29.000 inserts para 34.000 não chegou nos 40.000 que eu queria mas por hora resolvi subir meu pull request que também tem link na descrição abaixo e pular pra outra coisa só para terminar esse dia 4 de setembro eu fui dar uma fuçada na tal versão em dnet do André e Albert que alcançaram o terceiro lugar como muitos outros eles também optaram por fazer uma versão codificada de forma rápida Sem muitas boas práticas então ficou bem verbose e tudo super longo a curiosidade é que como muitos também optaram por implementar um Cash mais diferente da maioria em vez de redis escolheram usar nats nats deveria ser mais usado e parece que povo de dot net usa mais é uma alternativa até mais confiável do que redis para funções de cash ou como uma fila de job simples em cima do nats usaram os recursos de A5 do csharp com channels para fazer a implementação de book insert E com isso atingiram quase o máximo 44.000 inserts essa versão eu não mexi em nada só fito it a respeito no dia seguinte dia 5 de setembro me sugeriram fuçar alguma versão de PHP então puxei para rodar a versão do Lauro apelt que ficou em 17º lugar no ranking com meros 25.000 inserts fazia muitos anos que eu não mexia com PHP então eu precisei da ajuda dos Universitários pacotes de PHP hoje em dia se instalam com composer que é parecido com npm de JavaScript ou cargo de Rust foram-se os dias de baixar Zip de sites como fresh meat ou source Ford mas PHP ainda tem o conceito de extensions que como o nome diz carrega junto com o PHP e modificam as estruturas internas da linguagem Antigamente eu lembro de usar Pier que eram as extensions em C mas hoje parece que são pe ou picle nesse estágio precisava carregar essa nova extension chamada swol que adiciona funcionalidades de cor rotinas e modelos de io não bloqueante o que transforma o PHP em algo parecido com o node JS basta baixar compilar instalar extension e editar o php.in para carregar ela na inicialização depois de bater cabeça para entender isso e instalar os pacotes eu pude rodar essa versão do Lauro que ele implementou com o Framework hyperf php7 tem uma sintaxe bem mais moderna do que o antigo php3 que eu usava mais de 20 anos atrás mudou bastante coisa tá bem mais legível bem mais organizado e o Lauro foi um dos poucos que deu uma caprichada e deixou tudo fácil de entender ilegível recomendo darem uma olhada Nessa versão também não mexi em nada do código Só parei para entender desenferrujar um pouco do meu PHP a única coisa que eu ajustei foi o pull de conexões aqui ao contrário da maioria o Lauro foi super conservador e limitou o uso de conexões com 10 conexões muito pouco resolvi soltar tudo e jogar lá para cima Em 500 que é exagerado mas fazendo isso e rodando o stress teste essa versão também subiu para quase 40.000 inserts o que também eu colocaria lá pelos top C por causa disso já me dei por satisfeito Por enquanto já que queria pular para ver outras versões nesse dia eu não mexi muita coisa dei uma pausa e à noite resolvi que ia mexer mais no dia seguinte mas acabei não conseguindo dormir levantei e Voltei pro PC queria mexer em pelo menos mais uma versão a de Python escolhi o 21º lugar do Ian cambrea com menos de 24.000 inserts ele não fez em Jungle que seria mais comum paraa web em geral nem em Fast api que pareceu mais comum para apis Ele Escolheu Sonic que é um Framework que eu não conhecia a única modificação significativa que eu fiz foi notar que ele também resolveu usar redis para Cash mas não implementou um pull de conexões pro redis tava usando uma única conexão para tudo não não consigo afirmar que era só isso mas testando na minha máquina como os outros o resultado bateu nos 40.000 inserts também de curiosidade Essa foi a única versão que eu vi que usou innex diferente normalmente a gente configura innex para fazer balanceamento de carga usando protocolo http portanto usando rede TCP por baixo fazendo proxy reverso para outro servidor web http atrás no caso um Sonic mas emex e outros serviços que rodam em Linux Como o próprio posts que também costumamos conectar via TCP na porta 5432 suportam conexões usando Unix sockets se tudo for rodar na mesma máquina que não é comum no mundo real não tem necessidade de usar rede TCP iip tá tudo na mesma máquina podemos fazer um processo se comunicar diretamente com outro processo usando IPC ou interprocess communication e um dos jeitos de fazer isso é via Unix sockets de forma resumida sabe quando fazemos tipo um Cat num arquivo adicionamos um Pipe rodamos um grap do outro lado para filtrar o conteúdo desse arquivo isso é um jeito do processo grap se comunicar com o processo Cat via esse Pipe que liga o STD out do catch ao STD in do grap é mais ou menos isso que acontece com nnex usando Unix sockets para falar com as instâncias de Sonic basta todos enxergarem os mesmos arquivos psoc depois deem uma olhada no repositório do iam para ver como ele fez como a versão de Python também foi fácil e não exigiu nenhum trabalho meu além de ajustes triviais eu fui dormir e no dia seguinte resolvi olhar pro topo da lista de novo eu fiquei curioso com isso de Link 4 que a Sofia e a Gabi usaram e alcançaram o top 4ro do ranking nunca tinha ouvido falar nessa linguagem mas o que eu vi foi impressionante Link 4 é uma linguagem experimental ainda longe de ser 1.0 criada na Microsoft research pelo brasileiro Leonardo de Moura em 2013 o objetivo dele foi criar uma linguagem para ser fácil criar prova de teoremas é uma linguagem mais focada em formalidades matemáticas inspiradas em linguagens funcionais como husk ou Kel ele tem um cheiro de dialeto de linguagem da família ml se curte linguagens funcionais e formalidade matemática essa pode ser uma boa alternativa mais impressionante foi a dupla algebraic as autoras do projeto da rinha a Sofia que tem só 21 anos e a Gabi que tem só 17 ou 18 anos como eu falei desde o começo implementar esses end Point de ap e em si não é nenhum desafio mas nesse caso foi LM 4 sendo experimental comunidade pequena e quase nada paraa web porque nunca foi o foco ela é quase toda focada em teoremas matemáticos não queria apis pra web para fazer apis elas precisavam de um parcer de Jason já que na regra da rinha o stress test ia mandar milhares de requisições com Jason mas não tinha uma biblioteca de Jason então a Sofia fez um do zero Quando se recebe as requisições http algumas contendo esses Jason precisa conseguir parcial o pacote existe já parcer de http em C que todo mundo usa em várias linguagens mas para LM 4 não tinha então a Sofia fez um wrapper em ffi para integrar para implementar a aplicação em si ela queria usar algum Framework web como in node você tem Express ou em Java tem Spring mas em Link 4 não tinha então a Sofia fez um pequeno do zero Além disso para rodar uma aplicação web D precisa de um servidor web sabe tipo nodejs tipo web tupie tipo Tomcat e claro também não tinha e claro a Sofia fez um ou seja esse foi aquele caso de não sabendo que era impossível foi lá e fez só esse esforço já merece uma menção honrosa porque eu acho que ninguém teve metade do trabalho que Elas tiveram mais [ __ ] ainda porque essa versão foi uma das mais performáticas também é igualmente impressionante que uma linguagem desconhecida experimental E que provavelmente ninguém nunca usou pra web seja tão performática criador Leonardo f em fazer uma linguagem com objetivo de provar teoremas e verificação formal em vez de performance bruta mesmo assim foi bem sucedido em performance não deixem de olhar o código da rinha do repositório da Gabi além das bibliotecas no repositório da Sofia links abaixo no vídeo de análise do Mr Power gamer br onde ele descobriu os limites do stress Test e das regras da rinha também conseguiu identificar que algumas das versões nos top 10 tinham bugs como de validação que acabaram deixando passar L inserts que não deveriam em particular por falta de validação de data essa versão em lin 4 tinha esse tipo de bug elas Esqueceram de colocar validação da data de nascimento e tudo bem mesmo com a validação a versão delas ainda ia ficar entre os top 10 por pouco então eu aproveitei para tentar molhar meus dedos em LM 4 pela primeira vez e implementei uma validação simples foi o código menos intuitivo que eu fiz em muito tempo eu acredito que quem for mais experiente em linguagens como haskel devem conseguir entender um pouco mais fácil fácil tinha outro pequeno bugzinho na hora de gerar o RL pro cabeçalho de location depois de inserir o registro no banco então eu corrigi isso também de qualquer forma Vejam o link dos meus pull requests na sessão de links abaixo no fim desse dia eu postei um tweet de resumo até esse momento com tudo que eu descobri nesse estágio da minha Saga já tinha conseguido fazer minha própria versão de rails e de Crystal bater os 40.000 inserts ajustei a versão ine do Lucas elixir do Gabriel GO do Luan PHP do Lauro Python do Ian além dos ajustes no link da Sofia e Gabi chegamos no dia 6 de setembro véspera de feriado prolongado de independência e que eu tinha planejado viajar depois de ter batido cabeça com LM 4 resolvi que eu queria bater cabeça com outra linguagem que eu nunca mexi antes tentei fuçar Zig mas achei que tava experimental demais mental super instável na verdade tudo instável coisas da versão 0.10 quebram na 0.12 para uma experiência de um dia só não ia compensar eu acho acho que é uma das linguagens mais promissoras tanto que foi usado para fazer o novo Ban mas eu vou deixar para outra ocasião então eu lembrei que sempre quis tentar a linguagem nim outra que é compilada como go tem uma sintaxe inspirada em Python existe Já faz alguns anos então assumi que seria mais estável e melhor documentado do que Zig provavelmente fácil de chegar numa boa performance assim como eu consegui com Crystal e Ledo engando apanhei bastante a começar pela falta de documentação não ajudou nada que a biblioteca assíncrona para postgress se chama assim que pedi que é o mesmo nome da de Python quando pesquisa no Google adivinha quem aparece primeiro para piorar a linguagem e suas bibliotecas usam e abusam de macros que modificam a sintaxe da linguagem sem ter uma boa experiência foi confuso diferencial o que era da linguagem e o que eram macros as mensagens de erro do compilador confundiam mais do que ajudavam reclamações de amador claro eu não tô dizendo que é um defeito mas é uma curva de aprendizado maior para iniciantes recursos de cor rotinas tipos como option pareciam ainda meio experimentais com hacks para funcionar certas sintaxes eu escolhi o Framework web Jasper que parece um Sinatra de Ruby apanhei um bocado mas eu consegui implementar os quatro end points Numa manhã só que contrário às minhas expectativas o resultado foi pífio uma verdadeira droga mesmo já tentei compilar com a opção Speed nada já tentei compilar com modo multi Red nada suspeito que a Biblioteca de a pool que eu tô usando é imatura e vaza conexões depois eu preciso investigar isso melhor mesmo aumentando o Pool para 100 ou mais nem chega até o fim do stress teste abre o bico muito antes mem em série 2000 inserts isso deixaria essa versão lá no fim do ranking oficial só ganhando da versão de brincadeira feita em besh do Leandro a probabilidade maior é que eu sendo amador posso ter feito erros de iniciante e por isso foi ruim mas na maioria das linguagens mais maduras um iniciante teria dificuldade de deixar tão lento assim mesmo se fosse no JavaScript se tiver alguém assistindo que tem experiência com nin Não deixe de dar uma olhada no meu P request linkado abaixo para ver se descobre o problema mas no estado que tá agora eu não recomendaria usar nin para uma aplicação web mesmo se fosse Bem Simples se for para usar uma linguagem imatura com bibliotecas instáveis e mal testadas é melhor ir direto pra Zig ou veng que são mais modernas Apesar dessa tentativa frustrada outros desenvolvedores acompanhando a minha Saga começaram a se mexer para fazer versões melhores por exemplo nesse mesmo dia eu vi o Júnior Leão mostrando uma outra versão em Java com Spring boot usando redis PR Cash com jdbc direto e também Conseguiu alcançar os 40.000 inserts outra tentativa bem sucedida foi do Carlos Silva conhecido como insalubre que tinha participado com a versão em veng mas tinha algum problema e ele foi desclassificado Então nem entrou no ranking oficial vlang é uma nova linguagem com cara de GO ele se inspirou nas discussões de técnicas que fizemos no Twitter consertou a dele e atingiu os 46.000 inserts o Leandro continuou mexendo na sua versão de Ruby e nesse dia reportou que conseguiu bater os 46.000 inserts ele foi quem mais testou a hipótese de diminuir a porta de entrada do nginx e controlar a vazão de requisições com só 256 workers do nginx e 30 conexões totais de posts no Pool com Conseguiu alcançar os 46.000 inserts demonstrando que nem o ngex e nem o postgress nunca foram os gargalos dessa rinha veja o fio do tweet dele nos links abaixo para mais detalhes no fim do dia eu resumi num tweet todas as técnicas que descobrimos até agora por exemplo validação pode consumir tempo precioso quanto mais otimizar melhor não precisa devolver mensagens de erro elaboradas muito menos em Jason só o cabeçalho http com o código de erro tá ótimo e vai ser mais rápido o posts não é o gargalo não com essa quantidade de mixuruca de dados 50.000 inserts não é nenhum peido por isso não precisa tentar otimizar prematuramente com redis para Cash linguagens que escalam com trads ou Forks precisam de mais conexões com o banco um exclusivo para cada trad Então tem que dar um pouco mais de Ram pro banco subir essas conexões extras cada conexão de posts custa caro uns 2 A 3 MB porque são Fort então sem conexão exigem no mínimo 300 MB e ainda tem que sobrar ram para processar as queries ou seja menos de 500 MB é inviável linguagens com suporte a fibers exigem um pouco menos conexões porque compartilham a mesma conexão na mesma tred de novo tá anotado já para eu explicar isso no próximo episódio uma coisa que eu e o Mr Power gamer br vimos na implementação vencedora em Rust do Vinícius Fonseca é que ele entendeu Mas nem todo mundo pensou na forma correta de lidar com search fuz e do posts também já anotamos para explicar no próximo episódio o Vinícius fez certinho Ao tornar o search mais eficiente sobra mais CPU pro postgis conseguir lidar com os inserts e por fim o mais importante é lembrar do conceito de controlar a vazão na entrada diminuindo quantidade de workers de ngex esse nunca foi o gargalo com meio CPU e quase nada de Ram aguenta todas as requisições do stress test sem reclamar alguns não gostam de nginx porque algo como Fest http de GO é muito mais eficiente mas nessa rinha o ngex Nem chega perto de ser gargalo colocando 0.15 CPU e uns 200 MB pro nginx perto de 175 CPU e pelo menos 1.2 GB de Ram pro posts daria para colocar um pull exagerado de mais de 200 conexões embora o 100 padrão no total seja suficiente pra maioria O que sobrar Dá para dividir com sua aplicação ou seja p3 CPU e até 88 GB de Ram para cada instância Depende se sua aplicação for mais pesada que isso como as versões em Java ou rail ou mesmo node aí precisei ir tirando e testando de p05 em p05 do posts dando pra aplicação e medindo para ver os limites e chegamos No feriadão de 7 de Setembro Apesar de eu est coando para investigar mais códigos da rinha eu tive que parar por alguns dias eu corri para tentar desvendar tudo antes do feriado e apesar de ter conseguido ajustar várias versões para chegar nos 40.000 inserts ainda tava coçando aab cça com elusivo máximo de 46.000 tinha algumas suspeitas para testar quando voltasse mas eu fui viajar com essa pulga atrás da orelha ainda já tinha planejado de levar minha namorada para conhecer Gramado no Rio Grande do Sul nos divertimos bastante apesar de est super cheio e com tempo meio duvidoso visitamos diversas atrações como a super carros onde eu pude fazer teste drive de Ferrari Nissan GTR mas esse vídeo não é de turismo quem me acompanhou no Instagram viu as Stories em tempo real se não acompanhou e ficou curioso eu deixei um destaque lá procurem o link na descrição abaixo Mesmo durante o feriado vários desenvolvedores continuaram empenhados em desvendar os mistérios da rinha e na sexta-feira dia 8 de Setembro outro dos participantes o Vinícius Ferraz fez uma descoberta muito importante ele titou assim você que participou da rinha tomou um io Exception premature Close tonou o banco sua aplicação innex não conseguiu resolver 100% sabe Onde poderia estar o problema na rede do docker como resolver Network mode host em todos os serviços Caraca nas primeiras versões que eu mexi na minha em rails em Crystal AD node onde eu gastei mais horas chegava perto dos 40.000 39.000 o comportamento ficava estranho olhando no gráfico não tinha muita explicação ficava nesse tremido esquisito no fim do gráfico como se tivesse tentando ultrapassar um teto invisível mesmo nas versões vencedoras como o Rust do Vin dava para ver um tremidinho menor no final mas ele conseguia aguentar até o fim independente da versão mais cedo ou mais tarde aparecia isso eram requisições que começavam a se perder Não perdia tudo nos insertos mas principalmente nas pesquisas por termo até em pesquisas inválidas o que era mais absurdo já que só checa se o parâmetro de termo não existe devolve cabeçalho de erro esse endp nunca tinha que dar noout porque não processa nada como teve Aquele caso do elixer do Gabriel que descobrimos que meu sistema mandar baseado em Arc Linux tem o limite maior e por isso afetava o uso de memória do erlang imaginava que tinha alguma coisa na minha infra que também pudesse est afetando isso cheguei a suspeitar do podman que eu tava usando no lugar do docker mas não deu tempo para investigar isso porque chegou o feriadão e eu fui obrigado a parar e era mesmo no docker e o mesmo problema acontece no podman explicando quando Subimos contêiner de docker não é uma máquina virtual eu expliquei isso em detalhes no meu vídeo de docker então assistam lá depois o processo roda nativo no sistema operacional host só que a infra do runc de Linux que é a base do Doc e do podman nos dá opção de enganar o processo rodando uma dessas formas é quando mapeamos volumes dizemos que um diretório dentro do contêiner na verdade mapeia para outro diretório do lado de fora no HOST o mesmo vale pra rede Digamos que eu queira subir vários poges na mesma máquina não ia conseguir porque o primeiro ia subir e dar bind na porta 5432 o segundo ia tentar dar na mesma porta Mas como já tá ocupado ia falhar com contêiners cada processo consegue dar bind na porta 5432 de uma rede falsa virtual Ele acha que tá sozinho na máquina Daí podemos mapear a porta interna do contêiner para uma porta na rede de verdade do lado de fora Para isso precisamos de uma ponte de rede um Bridge que é o modo de rede ou Network mode padrão mas podemos escolher fazer bind direto na porta da rede de verdade do host é isso que o Vinícius sugeriu Network mode host ao não usar o modo ponte estamos retirando o gargalo da tradução de tráfego da rede virtual pra rede de verdade isso custa recursos é mais pesado não existe almoço grátis tudo custa alguma coisa O que a gente não sabia é que era pesado a ponto de afetar esse stress test sem querer esse era o elo perdido da rinha a última peça que faltava e só para me deixar ainda mais ansioso para votar do feriadão no domingo dia 10 o o desenvolvedor Reinaldo resolveu fazer uma versão nova em Java usando quarkus reactive vertex seguindo as dicas do Bruno Borges e Vinícius Ferraz depois Vejam o repositório dele o usuário é Zi Santana ele titou como conseguiu uma versão que atingia mais de 51.000 inserts mas já falamos que o máximo é 46.500 e tanto portanto certamente essa versão tem bug de validações como eu demonstrei na versão em lin 4 da Sofia mais importante essa versão em Java a atingia um critério que a rinha não media mas que para mim era importante eu passei os últimos dias tentando entender porque ninguém atingia zero knockouts não perder nenhuma requisição Esse é o ponto onde vencemos o stress test entenderam até esse momento a noção era que o stress teste era tão pesado que nenhuma aplicação conseguia segurar tudo e eventualmente ia perder requisições alguns mais alguns menos isso é comum em testes de carga mas assim como endex e posts n nunca for o gargalo a carga também nunca foi tão pesada assim quando o Zan Foi testar os participantes para encontrar os finalistas o teste ainda era mais leve ele dobrou o teste senão todo mundo ia passar mas mesmo dobrando ainda não é pesado o suficiente todos os testes que eu fiz até agora foi com essa versão já dobrada é importante ter essas ordens de grandeza em mente vamos deixar notado porque eu quero explicar isso para vocês o que significa sessões simultâneas tempo de resposta frut faixa de c 50.000 linhas numa tabela é super leve para um banco de dados como postgress só vamos sentir que ele tá pedindo água quando atingirmos faixa de milhões de linhas e isso se tiver sem índices adequados 600 sessões fazendo requisições não é pesado mesmo com a restrição de menos de um CPU no docker compos 1000 sessões simultâneas continua não sendo pesado a viagem de volta de Gramado foi cansativa varamos noite no domingo pra segunda eu tava de carro alugado e saímos com 2 horas da manhã de Gramado para devolver o carro às 4 horas em Porto Alegre e pegar o voo de volta para Congonhas em São Paulo às 6 horas pegamos táxi perto das 9 horas da manhã antes das 10 horas chegamos em casa eu só pude constelar rapidinho no avião e quando cheguei já liguei Meu PC a primeira versão que eu queria testar foi a de Crystal com Luck eu troquei o Network mode no docker compose para host e foi era isso bateu 47.000 inserts provavelmente ainda tinha algum bugzinho de validação porque ultrapassou o máximo zero nocs sabe a tal tremida nos gráficos que eu falei liso até o fim uma linha reta em todos os gráficos era isso que eu sabia que o Crystal tinha capacidade e confirmamos a rede do docker que não tava deixando próxima versão eu mexi no meu rails over engineered con Kick e tudo mais Network mode host e bateu acima de 45.000 insertos faltou pouco para atingir o máximo dos 46.000 e tantos eu não gastei muito tempo a estando valores no docker compos mas mesmo assim deu só 4% de knockouts antes dava 20 30% ou mais mas isso prova meu ponto gargalo nunca foi nem falta de CPU nem falta de ram nem pogs nem nginx era problema de io e isso é gerenciava em quase qualquer linguagem se Crystal e Ruby batem o máximo qualquer outra deveria conseguir peguei a versão de lan 4 e ainda tem algum bug de validação mas bate acima dos 47.000 inserts mais uma versão que vem stress teste sem suar eu peguei a versão em node JS do Lucas também bateu no máximo de 46.000 e tantos e isso foi se repetindo a versão em Python e Sonic do Ian cambrea a versão em veng do Carlos a versão em go do Luan a de PHP com suul do Lauro e a outra versão em rails do Lázaro todos batem o máximo e de bônus eu resolvi testar a versão em c+ Plus do Lucas William que tinha ficado em 12º lugar com menos de 35.000 inserts também bate perto do máximo Agora 43.000 inserts não bateu por algum bug na validação Enquanto algumas versões faltavam validação e deixava inserir mais que o máximo Nessa versão tem alguma coisa filtrando demais e impedindo de gravar mais olhando os gráficos claramente podemos ver que tá sobrando recursos zero knockouts não tá perdendo requisições então tem recursos sobrando nessa segunda-feira tava todo mundo só falando do lançamento da versão 1.0 do ban a nova alternativ ativa a node JS deno que promete ser mais performático ainda é cedo para dizer e ainda nem é totalmente compatível mas o URI Gomes tinha participado da rinha com a versão pré-lançamento do ban 0.8 e tinha ficado em 14º lugar com menos de 28.000 inserts mas com Network mode em host ele também bateu o máximo e com tempos similares da versão de Rust nesse exemplo com escopo pequeno seu desempenho foi à altura do Hype O que é bem promissor alguns ficaram me cutucando para mexer em C Sharp também eu não tinha mexido em nenhum até agora porque a versão do André e do Albert já provaram que alcançava o máximo mas nada mais justo do que finalizar essa segunda-feira super corrida pós feriado do que avaliar a versão do nosso querido organizador da rinha Zan francesc por coincidência ele participou com uma versão de dnet Eu não vi ele no ranking oficial Eu acho que como organizador ele se absteve de se colocar na disputa participou pela diversão mesmo mas cometeu o mesmo erro que eu e outros Assumimos que pogas ia seu gargalo e colocamos cash de redis antes de realmente medir a necessidade mas eu espero que essa altura tenha ficado claro que posters nunca foi o gargalo Não tô dizendo que nunca é em outros projetos vai ser mas nesse desafio não era por isso é caso a caso precisa medir por causa disso ele implementou um Cash em memória usando um concurrent Dictionary lembra aquelas pesquisas com select like que Eu mencionei antes no post index Arms com gist e trigrams fica bem rápido mas como a estrutura rudimentar como um dicionário um hash ele é obrigado a percorrer 100% do dicionário o tempo todo extremamente lento isso limitou o resultado a 40.000 inserts eu tentei fazer os mesmos ajustes de todo mundo limitar vazão do dnex mexer no P de conexões dividir melhor recursos do docker compose colocar em Network mode host mesmo assim não dava minha suspeita é que esse concurrent Dictionary matou essa versão e Se alguém quiser tentar tirar e retestar vá no repositório dele nos links abaixo de qualquer forma com a ajuda de todo mundo do Leandro Mr Power Gamer Gabriel Oliveira Vinícius Ferraz e outros conseguimos atingir o objetivo não oficial que eu estabeleci pra rinha vencer o stress Test e colocar todas as linguagens no mesmo primeiro lugar ou dentro dos top três fizemos isso com três versões de Ruby nodejs PHP Python Java cotlin Ban vlang golang Cry c+ Plus Todo mundo bateu os máximos as duas exceções que não bateram foi A de C Sharp do Zan e a de elixir do Gabriel Em ambos os casos eu acho que a lógica de cashing gargalo que é lição aprendida não faça otimização prematura em vez de ficar mais rápido pode ficar mais lento se tirar esse Cash provavelmente bateria os top três e falando em top um agora que eu consegui cumprir minha missão nessa rinha só faltava uma última coisa que eu queria fazer desenferrujar o meu Rust mexendo na versão do ganhador oficial O Vinícius Fonseca e finalmente Chegamos no 16º dia da minha Saga dia 13 de setembro assim como a versão em c+ Plus do Lucas ou em node do outro Lucas que colocaram tudo no arquivo só o Vinícius fez a mesma coisa em Rust repetindo é uma rinha o critério não era o código durar para sempre era só aguentar o stress teste beleza do código mantenabilidade legibilidade segurança nada disso eram critérios eu que fui narigudo e fui Fi fuçando e mexendo no código dos outros sem ninguém pedir meu objetivo era só desenferrujar os meus Skills uma boa forma de fazer isso era pegar o código dos outros e sair reorganizando essa foi a primeira coisa que eu fiz no código do Vinícius refatorar Rust já não é uma linguagem muito fácil de bater o olho cheio de annotations um monte de ponto Clone pon un WP tipos genics para lá e para cá e tudo amontoado dividindo em modos fica mais fácil de bater olho Mas eu queria corrigir o bug que o Mr Power Gamer identificou na análise dele a condição de corrida que acabava deixando sobrar mais linhas na tabela do que o máximo possível isso acontece porque o Vinícius manda inserir mais de 500 linhas na inicialização para algum tipo de aquecimento Que eu saiba o Rush não tem e nem precisa de um jus in Time compiler um DIT Já que é pré compilado em binário aquecimento faz mais sentido pra Java que tem em DIT enfim ele deixa essa rotina rodando numa cor rotina da biblioteca Tókio a mais famosa que dá suporte a semântica de Future o equivalente a Promises de node JS na sequência inicia um segundo Future assíncrono essa rotina tem um timer um slip de 2 segundos quando passa 2 segundos manda um comando de SQL para deletar as linhas de aquecimento e é aqui que acontece a condição de corrida nada garante que 2 segundos é suficiente para inserir essas 500 linhas muitas vezes o delite acontece antes daí sobra linhas na tabela não havia necessidade do delite tá no future separado basta estava disparar o delite depois do último insert ou uma gambia seria aumentar esse timer de dois para mais segundos e eu fiz isso e para garantir alterei o último end Point o de Contagem final da tabela para filtrar os registros de aquecimento com isso batemos os mesmos 46.000 e tantos insertos como todo mundo depois dei uma olhada no meu P request para conseguir entender melhor essa versão de Rust eu não curto competições de código não porque eu sou contra cada um com seu entretenimento não tem nada de errado em competir com código só não pode achar que código de competição é a mesma coisa que código para projeto de verdade as técnicas são diferentes os requerimentos são diferentes muitos truques que Eu mencionei não devem ser usados sem critério vai dar errado e nenhuma comparação generalizada pode ser feita entre as diferentes tecnologias usadas uma competição no estilo dessa rinha serve para mostrar quem foi mais esperto quem teve mais sorte quem foi mais cuidadoso o Zan teve bastante trabalho para organ e para avaliar um a um cada rodada do stress teste do getlin custa 3 minutos 50 projetos que passaram significa que ele gastou quase 3 horas só esperando os testes rodarem Sem contar os outros projetos participantes que tinham bugs agora que passou É fácil dizer ah poderia ter feito x melhor poderia ter feito Y melhor mas a posterior tudo é fácil eu gastei mais de duas semanas avaliando 18 repositórios em 16 linguagens diferentes eu tive a sorte de contar com a contribuição de diversos outros desenvolvedores que se animaram para investigar junto acho que conseguimos desvendar todos os truques possíveis dessa rinha incluindo vencer o stress test do gatlin Mas isso não é competição é análise técnica não é divertido para todo mundo só para nós mais nerds mesmo se você for torcedor de um Neymar Messi Cristiano Ronaldo Seja lá quem acha que é o melhor jogador do mundo se no dia do jogo eles torcerem o tornozelo e não participarem O resultado vai ser o que der no dia quando perdem não significa que são ruins no geral só significa que perderam aquele jogo e ponto final é o conjunto da obra que determina os melhores e não um jogo individual sorte faz parte do jogo mesma coisa nessa rinha só porque um Java ou um PHP não apareceram no topo dessa vez não tem nenhuma correlação com a qualidade deles em outros jogos amador desbocado é quem faz mais barulho nas redes sociais então meu objetivo foi Educacional demonstrar porque estão errados e fazer todos entenderem que sim com mais tempo experiência e Skill qualquer uma das linguagens tinha a capacidade de alcançar resultados semelhantes alguns com mais trabalho alguns com menos trabalho alguns gastando mais recursos alguns menos não importa sua linguagem não te define assistiam os meus vídeos de sua linguagem não é especial o que que eu falei lá um bom desenvolvedor é promíscuo com linguagens eu mexo em qualquer uma a qualquer hora quando quiser e como quiser o que eu falei em vídeos como aprendendo a aprender ou aprendizado na vida do Caos várias das linguagens que eu mexi nessa Saga ou eu nunca tinha mexido como nin lin 4 veng ou tava enferrujado Fazia anos como c+ Plus C Sharp Rust go PHP Crystal mesmo linguagens que eu tenho um pouco mais de intimidade como Ruby JavaScript Python eu tive que quebrar a cabeça o que que eu fiz instalei uma a uma e fui fuçar o código dos outros quebrei elas várias vezes Consertei refat reorganizei Fiquei em muita tentativa e erro reimplementado Essa é a diferença as primeiras linguagens que aprender vai levar meses anos para dominar já as próximas vão ficando exponencialmente mais rápido de pegar o suficiente para conseguir fazer o básico novamente eu demonstrei esse ponto na prática em um dia já dá para fazer alguma coisa se me der alguns dias eu consigo me virar em qualquer uma em poucas semanas eu já vou saber truques avançados de cada uma eu consigo me tornar produtivo numa Linguagem Nova em um mês Onde eu vou levar mais tempo em linguagens que tem paradigmas muito diferentes como haskel o Camel F Sharp Closure ou o link 4 que vimos hoje com todos esses disclaimers e avisos feitos Ouçam até o final antes de sair comentando sim Rust e go aparecem no topo do ranking oficial porque se não cometer erros graves o tempo de resposta individual de cada requisição vai ficar na faixa de abaixo de 1 milissegundo de microssegundos frameworks como rails ou um laravel da vida vão responder na faixa de milissegundos quanto menor o tempo de resposta mais requisições Dá para responder no mesmo período de tempo Rust ou go realmente tem mais velocidade bruta e conseguiram bater a barreira acima dos 40.000 inserts mesmo com doken em modo ponte e chegar no máximo durante o evento e porque todo mundo não passa a adotar Rust go V leng Zig de uma vez tudo compilado em binário nativo super rápido vamos colocar assim não existe um motivo não pensem que as pessoas ou empresa são burras e não sabem que são rápidos se c+ Plus existem muito antes da maioria de vocês nascerem e sempre foram rápidos todo mundo sabe disso no caso de um veng ou Zig é fácil explicar é porque são novos demais e instáveis demais tem suporte baixo tem ferramental imaturo mudando o tempo todo e quebrando compatibilidade falta documentação na forma de livros cursos justamente porque ainda estão mudando muito esses não tem como ser adotados em larga escala só early adopters muito dedicados só em empresas menores com maior margem de assumir riscos com um cofounder ou diretor técnico muito bom para liderar mas tudo é uma questão Econômica não me stinga eu sou só mensageiro mas a realidade é que a enorme maioria dos programadores não tem capacidade de aprender a usar linguagens de baixo nível no nível que seria necessário para serem produtivos e produzir código bem feito o fato da maioria das empresas não tá desesperadamente procurando esse perfil é a evidência sempre existem exceções não comece com Ah mas eu conheço fulano ou ciclano exceção não define a regra fica a dica se tornar um programador avançado nas tecnologias mais difíceis te torna uma mosca branca que vale muito mais que os outros o que que eu sempre falo tudo que é fácil para você aprender também é fácil para qualquer outro quanto mais gente tiver fazendo a mesma coisa mais barato todos vão ser o valor tá em ser bom naquilo que poucos TM capacidade de conseguir onde a barreira é mais alta e isso vai ser Rust go c+ Plus para resolver problemas muito mais complicados do que fazer crudes ou apis reflitam sobre vocês mesmos Por que estão estudando Java ou csharp ou JavaScript porque são as posições que tem mais vagas Rust não se vê vagas todos os dias tão vendo é o problema do ovo e da galinha você não quer investir tempo para aprender Rush porque não vê vaga todo dia e as empresas não oferecem vagas porque não vem trou centos cursos e estudantes aprendendo por isso que esse tipo de movimento ou começa em startups arrojadas ou dentro de Gigantes como a Microsoft as vagas existem bem pouco e pagam bem só que são bem mais exigentes mas ninguém gosta de vaga difícil só querem as que acham fácil não é prático nem realista manter aplicações web complexas e gigantes em linguagens assim imagine um shopify github mercado livre Amazon iFood da Vida 100% em linguagens de baixo nível partes do sistema que são mais sensíveis à performance já adotam sim coisas como go mas é a menor parte para uso do dia a dia dashboards relatórios crudes e coisas assim não compensa Seria um enorme desperdício da tarefas consideradas commodity como fazer relatórios para um tipo de programador raro e caro com GO ou Rust adotar uma tecnologia só porque é mais rápida não é um bom argumento hoje em dia todas são rápidas o suficiente mesmo linguagem que um programador de Rust chamaria de lentas como JavaScript ou Python conseguimos atingir patamares similares com um custo um pouco maior de máquina como eu demonstrei aqui na maioria dos casos é possível dobrar triplicar tendo o conhecimento adequado sem quase modificar código Nem precisar jogar tudo fora e reescrever tudo em Rust é isso que programadores como eu fazemos no fim do dia dado a escassez de programadores de Rust ou go e a dificuldade de achar talentos que consigam ser treinar ados nisso em pouco tempo sai bem mais barato compensar com servidores mais parrudos alguns pensam que para dobrar performance da sua aplicação em PHP Java dtnet Python node precisa jogar tudo fora reescrever em go tá errado só vai garantir que os erros Por ignorância que foram cometidos com PHP vão se repetir em go programador ruim vai fazer código ruim em PHP ou em go não existe nenhuma garantia que vai ficar mais rápido se você você continua não sabendo porque o anterior tá valendo por outro lado por experiência eu já melhorei muito sistema de verdade mexendo nos 20% de problemas que dão 80% de retorno é sempre assim às vezes são besteiras de pouquíssimas linhas como as que eu mostrei durante esse vídeo como eu falei antes são vários motivos custo benefício sendo o principal no geral o maior problema é que é muito difícil formar bons programadores que consigam tirar vantagem dessas tecnologias o custo benefício não compensa não significa que essas linguagens não têm chance significa que esse mercado sempre vai ser de nicho mas para quem tem o talento e a capacidade é um nicho que paga muito melhor é só ser Bom enfim hoje eu só quis resumir minha saga de como eu explorei 16 linguagens claro que superficialmente em 16 dias não deu para detalhar cada truque Mas deixamos tudo anotado e no próximo vídeo eu vou explicar o truque por trás da mágica como tudo isso funciona por funciona e mais importante quando usar e quando não usar se ficaram com dúvidas mande nos comentários abaixo se curtiram o vídeo deixem o joinha assinem o canal e não deixe de compartilhar o vídeo com seus 